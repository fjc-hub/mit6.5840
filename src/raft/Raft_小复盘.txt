0.注意思考在Leader选举、日志备份这些功能上，Raft为什么要这样设计，这样实现比传统方式/暴力方式好在哪里。对比性理解

——1.Raft思想介绍
    本质：
        一种consensus algorithm、一个过半投票（quorum）系统，在任何时候为了完成任何操作，你必须凑够过半的服务器来批准相应的操作。
    
    quorum特性：
        ① 避免脑裂：最多只有一个网络分区会有过半的服务器，所以我们不可能有两个分区可以同时完成操作
        ② 过半交集（majority intersection）：
            假设有一系列操作需要完成，其中每一个操作都需要过半的节点批准，那么任意两个已完成的操作
            至少有一个节点知道这两个操作，即有一个重叠的节点。
            投票支持下一个操作的节点中，必然能找到之前的所有操作。
    
  **1.666 过半投票特性在Raft中的应用（可参考下文6.）
        一系列操作有两种：选举leader；leader日志备份到follower

        旧Leader“日志备份”操作需要获得过半raft节点同意后才能完成，那么必然有过半的raft节点保存了它的‘所有’日志，
        后续同意新Leader当选的过半节点中，也至少一个备份了旧leader的日志（即包含了旧Leader的‘所有’日志）
        两个过半集合中至少有一个重叠的节点（可以作为新旧Leader之间的桥梁，新leader可以从这个桥梁上面获取旧Leader的信息）

        Raft协议通过在Leader选举过程和日志备份过程增加限制，确保新leader只会是包含了旧leader所有日志的节点（参考22.Leader Completeness Property）
        其他共识算法可能允许任意节点当选，但新Leader需要与过半投票节点通信，从中找到包含旧leader所有日志的节点

        raft leader每次向follower备份日志时，虽然在RPC中只包含了日志数组的一个后缀，但是只有两份日志
        数组完全一致时，follower才会同意这次“日志备份”操作，这要求除后缀外的前缀也是相同的，隐式提交。
        raft通过Log Matching特性来实现这种‘快速’的日志备份机制

    raft协议核心功能 CAP Theorem？
        - 一致性：
            ① 实现强一致性，客户端发送的操作以相同的顺序在集群中不同节点上执行，未提交的操作都不执行
        
        - 可用性：
            ① 只要集群中不低于半数的raft节点之间能正常通信 那么就能正常对外服务。允许少部分机器故障
            ② 自动故障恢复，即使唯一的Leader节点crash，只要满足①，就能自动选举出新Leader

        - 分区容忍：

2.在“多数票决”的选举机制 + “允许不同节点任期号（TermId）不同”的特性 下，
  存不存在“选举出多个不同任期Term的leader节点”的情况？
    允许同时存在多个leader，但它们的任期一定不相同。
    相当于分布式网络脑裂（split brain）产生了多个网络分区，每个分区有自己的leader
    这种情况不会影响系统正确性，因为有“多数票决”机制，最多只有一个分区的操作可以获得多数票来提交操作
    同时还有8.1这种纠错机制

3.所谓raft kill是什么？
    leader节点只能发不能收的极端网络情况下，leader可以发送heartbeat刷新其他节点的“发起新选举的计时器”
    但是无法收到所有操作来自其他节点的vote，所以无法达成“多数投票”的提交commit条件，导致所有操作（选举，增加日志）
    都无法完成，服务瘫痪

4.注意“发起选举goroutine”，“选举投票handler”之间的死锁问题
    发起选举的goroutine中需要加锁保护raft node的部分状态；选举投票的rpc handler中也需要安全访问共享的状态
    这两个逻辑执行流是并发的，当raft node发起选举后收到一个RPC请求进入handler，不能让handler由于互斥无法继续执行
    否则会导致多台服务器构成“死锁”循环等待

5.RequestVote handler为什么需要幂等（idempotent），需要保证何种程度的幂等？
    此RPC接口如果不实现对相同<candidate候选人, term任期>的请求的幂等，此候选人可能由于超时重试发送多条RequestVote请求
    从而在一个raft node上获得同一个任期的多张选票，最终可能导致出现多个同任期的leader。
    这也是为什么持久化要保存voteFor和currentTerm这两个状态的主要原因（这两个参数唯一确定一张选票，要防止这张vote投给不同raft）

——*6.投票给candidate需要满足什么条件？这些条件用于维护什么？
    限制条件：只能投给日志 “at least up to date than me” 的节点：先比较log队列中最后一条log的任期号大小，再比较log队列的长度.
    产生效果：加了这个投票限制和“leader不提交旧leader的log”，保证新选出Leader的Logs中包含所有已经Committed的日志（论文中称为Leader Completeness Property）
    
    6.1 直观解释1：
        如果不加限制，那么不包含任何日志的节点都可能成为Leader。
        容易造成Committed日志的丢失，
        为了保证Committed日志不丢失，Raft协议要求（其他协议有其他方案）：保存了所有已经Committed日志的节点才能成为新Leader
        实现这一点要求只需在投票时加上这个限制，再加上最基本的“多数票决”机制，就能保证新Leader保存了之前所有已经Committed日志
        
    *6.2 直观解释2：（灵感来源1.）
        - 假设一个集群2n+1台节点，最初的1号Leader故障了，需要选举，选举前就至少有n+1个节点保存了所有Committed Logs（最后一条log保存需要前面的log都保存了才会返回accept给Leader）
        - 第二个新Leader想要选举成功，必然要获得至少一个“保存了所有Committed-Logs的节点”的同意！！！
        - 限制这个至少一个的“保存了所有Committed-Logs的节点”同意投票的逻辑，即可保证新Leader保存了所有已提交日志
        - 循环下去，无论Leader更换多少次，新Leader总包含所有已经提交的Log。
    有些共识算法可能允许任何节点成为Leader，只不过新Leader上任后需要先找到投票给自己的所有节点中找到保存了所有Committed Logs
    的节点（至少有一个），然后从它们哪里拿到所有已提交的日志。只不过raft为了减少RPC选择加限制而已


7.只限制“投票给log更长节点” 不先比较最后一个log的任期号会产生什么问题？
    这样无法保证“Leader Completeness Property”，如果选出缺少已提交日志的leader 会造成raft之间状态机状态永远无法一致

8.代码实现中需要Double-Check（此说法灵感来自本人对DCL设计模式的理解）的场景有哪些？
        并发编程时需要注意获取多把锁的场景或这类逻辑流：比如持有一把锁仍然尝试获取另一把锁，
    这可能发生在一个函数内外（甚至是一个本地函数和远程函数上，通过RPC把handler函数和本地串到一个逻辑流中）。
        将原本的共享变量访问块（临界区）分成多块时，后面的块可能使用前面块中保存自共享变量的临时变量，不能使用这类临时变量
    因为原来的共享变量可能在未持有锁的这段时间发生了变化，临时变量这个“副本”并不能感知到这个变化，可能造成“脏数据问题”
        在leaderElection选举函数中，并发请求其他节点投票这个过程中没有加锁，所以这段时间内raft的状态、任期号都可能变化，
    投票结束后会根据投票数更新raft节点的状态（共享），比如raft已经从candidate变为follower，任期号从term1变成了term2，
    但获得了半数选票，如果不对之前的状态进行Double-Check，则会将raft状态变更为leader，从而让raft使用term1的选票晋升为term2的leader
    （原过半数的投票结果只能说明raft可以当term1的leader），所以更新状态前需要检查raft当前的term任期号。raft的状态可以不用校验是否为candidate

    8.1 选举纠错机制：一轮选举结束后，允许暂时出现多台raft都认为自己是Leader，允许它们发送新增日志RPC以及自己的心跳给其他节点，
    当拥有高任期号的节点收到这些低任期号Leader的RPC消息时，会将自己的任期号响应给这些leader，最后它们会从leader退回到follower。
    这种纠错机制建立在：每次raft之间的通信都会交换term任期号，收到低任期号消息的raft不会执行操作，收到高任期号的raft会修改自身各种状态！！！
    
    8.2 灵感来源如下（摘抄自lab手册 https://pdos.csail.mit.edu/6.824/labs/raft-locking.txt）
        Rule 5: Be careful about assumptions across a drop and re-acquire of a
        lock. One place this can arise is when avoiding waiting with locks
        held. For example, this code to send vote RPCs is incorrect:

        rf.mu.Lock()
        rf.currentTerm += 1
        rf.state = Candidate
        for <each peer> {
            go func() {
            rf.mu.Lock()
            args.Term = rf.currentTerm
            rf.mu.Unlock()
            Call("Raft.RequestVote", &args, ...)
            // handle the reply...
            } ()
        }
        rf.mu.Unlock()

        The code sends each RPC in a separate goroutine. It's incorrect
        because args.Term may not be the same as the rf.currentTerm at which
        the surrounding code decided to become a Candidate. Lots of time may
        pass between when the surrounding code creates the goroutine and when
        the goroutine reads rf.currentTerm; for example, multiple terms may
        come and go, and the peer may no longer be a candidate. One way to fix
        this is for the created goroutine to use a copy of rf.currentTerm made
        while the outer code holds the lock. Similarly, reply-handling code
        after the Call() must re-check all relevant assumptions after
        re-acquiring the lock; for example, it should check that
        rf.currentTerm hasn't changed since the decision to become a
        candidate.
    

9.candidate节点每次发起选举时为什么要重置“新选举计时器”？
    如果本次选举没有产生leader，最好不要马上开始下一轮选举，所以重置计时器
    带随机化的重置 有利于错开各个节点的选举计时器过期时间点，减少分票split-vote的出现。
    计时器使用下一次选举执行时间（expire逻辑）表达，比使用“上一次心跳时间”更好写代码。
    同一个raft节点可能后台有多个不同term的选举goroutine，每次RPC收到答复后都要Double-Check当前状态和RPC前的状态，
    以决定答复是否有效

*10.使用Go中WaitGroup的遇到的问题
    Wait操作必须等待内部计数器归零才能返回。在代码里使用了它来实现并发地发送RPC，在最坏的情况下wait的goroutine
    需要等待一半的raft服务器超时才能返回，如果上层函数依赖这个返回才进行后续代码，比如可能会delay下一轮心跳，导致出现Leader未故障
    但仍发生新的、更高term任期号的选举。Leader没有压制住其他节点发起选举。
        P.S.在一些不需要等待全部任务都完成的场景使用了这个东西,导致等待时间过长，后面的任务被长时间延期。
    比如leader当前这轮心跳还没有发完（收到全部peers的答复）下一轮心跳的时间已经到了，由于上一轮心跳发送任务占用了CPU，当前轮次任务
    发不出去，造成leader无法suppress抑制其他节点发起选举。
        再比如之前选举时使用了WaitGroup来同步所有RequestVote请求完成后再判断票数、判断是否有更新的term，这导致在网络不稳定太多RPC
    请求超时的情况下，同步需要花很长的时间，进而整个选举耗时超过其他节点的“选举计时器”：
         A节点发起任期T的选举                                                    B节点开始任期T+1的选举
                |                                                <<==发送T+1的RequestVote=|
      检测到更新的任期号term T+1                                                           |
       回退到Follower状态                                                                  | 
                |=将T+1任期的票投给B==>>                                                   |
                |                                                                         |
                |                                                                         |
          选举计时器过期                                                                    |
         发起T+1任期的选举                                                                  | 
                |=发送T+2的RequestVote==>>                                                 |
                |                                                            检测到检测到更新的任期号term T+2
                |                                                                回退到Follower状态 
                |                                                    <<==将T+2任期的票投给A=|
                |                                                                          |
                |                                                                    选举计时器过期 
                |                                                                   发起T+3任期的选举
                |                                                  <<==发送T+3的RequestVote=|
                |                                                                          |
                |                                                                          |
      检测到更新的任期号term T+3                                                             |
       回退到Follower状态                                                                   |
                |=将T+3任期的票投给B==>>                                                    |
                |                                                                          |
          选举计时器过期                                                                    |
         发起T+1任期的选举                                                                  |
                |=发送T+2的RequestVote==>>                                                  |
                |                                                                          |

    上图是一个只有两个节点的网络，可以看到每个raft节点在收到足够的投票后没有即使结束选举并发送心跳给其他节点（造成这种情况的原因有很多，
    比如上文提到的candidate节点使用wg等待所有raft回送RPC消息，包括故障无法处理RPC的raft），投过票的节点等不到刷新计数器的heartbeat
    便发起新一轮的选举，上一轮中获得足够半数选票的节点检测到更新的任期号自动回退为follower，如此往复，选不出Leader

11.注意活锁livelock问题
    see see 第10点

12.为什么上层应用向Raft投递命令要使用非阻塞non-blocking的方式（调用Start投递日志后立即返回）？
    raft需要把log备份到多数节点上才会返回客户端的请求，耗时比较长。
    采用“消息队列”的形式可以解耦raft和上层应用


13.日志结构
                                  rf.LastApplied                        rf.CommitIndex
    |--------Committed, Applied---------|---------Committed, Unapplied---------|-----Uncommitted-------|
    [<---已经提交并应用到状态机上的log--->][<---已经提交还未应用到状态机上的log--->][<---未提交的临时日志--->]
    
14.leader节点备份replicate自身日志给follower节点时，对follower节点保存了多少日志，有多少与自己相同
   以及“第一条与leader不同的日志的索引号”都是未知的。leader需要多次调用appendLog多次尝试来确定上述问题 并发送follower真正缺失的部分。
   leader是从第一条log开始or从中间某个位置or从最后一条log开始尝试呢？（目的是找到第一条不同的日志，然后发送后续所有日志给follower备份）
     从第一条开始，如果系统运行了很长时间，遍历比较耗时，从最后一条开始开始，如果follower落后leader太多依旧比较耗时
     从某一个位置开始比较好，由leader为每个follower都维护一个位置，后续同步从这个位置向前查找第一条不同日志的index，对于一个稳定且
     leader发生故障不多的系统是一个好方案（显然 leader发生故障后这个信息就丢失了，新leader需要从第一条或最后一条重新摸索）
     
15.leader发起的appendLogs操作获得多数投票后leader会在本地执行commit，但投票赞成的follower只是把这一批log赞存在自己log队列中还没有提交，
   follower们等着leader提交后发送提交信号-ACK确认后才能提交。leader一般是把可提交RPC-ACK捆绑到“下一次”appendLogs请求中（ACK合并）
   leader可以把ACK合并到心跳中吗？
      可以，appendLogs和heartbeat请求唯一的区别是heartbeat中的不包含log，其他参数依旧传了，对同一个follower的日志备份和心跳操作
      可以分配到同一个goroutine中处理

16.为什么leader需要给每个node在后台开启一个单独的goroutine来执行Log Replication呢？
    因为每个follower缺少的日志可能不同，与Leader的同步程度不同，比如一些节点和leader一样保存了1万条日志，少数节点一条日志都没有。
    leader需要多次RPC才能确定每个节点保存了多少日志，从而确定Log Replication该从哪一条日志开始。因地制宜
    而且根据集群中服务器数量一般不会太多，开goroutine无压力

17.Raft如何保证Log Matching Property（参考原论文5.3和Figure 3）？
        Log Matching Property是指任意两条备份在不同服务器上的日志，如果它们的term和index（在logs数组中的索引）一致，
    则：它们保存了相同的命令，是同一条日志；且它们之前的日志也是相同的。
        这个性质表明：①<term，index>唯一确定系统中的一条日志；②不同机器上备份的日志数组两两之间具有相同前缀。大大简化了leader日志备份任务
    如何保证实现这条性质呢？
        ①日志的<term，index>不可更改，一旦保存到Leader的logs数组中确定好顺序（index）号，在这个leader的任期内相同index不会再被分配出去
        ②follower备份来自leader的日志前，先检查备份开始位置之前的日志是否和leader相同，如果相同才append/overwrite来自leader的这一批日志
          只有前面日志相同的情况下，follower才允许对本地日志队列进行追加，所以从log队列为空开始“归纳”可以得出结论


——18.Leader备份日志时，为什么不能提交previous term的日志（参考原论文5.4.2）？
    任何限制条件都是： ！！！为了防止Leader覆盖follower中已经提交的日志！！！
    因为新Leader刚上任无法“马上”确定非自己任期内收到log有没有被对应老Leader提交，存在各种可能：
        1.这些log已经备份到多数节点上，Leader已经发送ACK向followers确认提交，也可能没有。这种情况下commit是安全的
        2.这些log没有commit，只复制到少数节点上，这种情况下新leader可以丢弃这些logs，更没必要replicate并且commit
    Raft协议允许在日志数组同一个索引使用term更大的log覆盖term更小的log，
    如果允许Leader提交一些previous term的log，这些提交的log可能被

    所以先不发ACK 直到收到currentTerm的log一起ACK

    committed日志定义
        原论文中的表述：A log entry is committed once the leader that created the entry has replicated it 
        on a majority of the servers。
        有一个subtle的点是：“he leader that created the entry”，创建/收到这条日志的Leader


*19.哪些需要RPC的任务可以异步执行？即下一次执行不需要等待上一次执行结束
    异步执行特点：无需等待同步。如果本次操作的耗时太长会延迟下一次操作执行，下一次操作不依赖前一次操作是否完成，
                 但会使这些操作重新排序 （乱序执行）。
    同步执行特点：能保证操作之间有序，串行执行。

    在RPC场景下，即使串行发送RPC请求，经过网络后，永远也无法保证接收方一定按发送顺序接收消息。
    也不能保证发送方按它发送请求的顺序收到响应。（使用网络 == 享受极致的乱序吧）

    1.每一轮选举：
        如果等待上一轮选举结束，可以由于少数节点故障或者网络延迟导致本轮选举中有少数节点没有答复，即出现“少数节点的问题导致整体无法继续”的情况
        所以，如果选举计时器超时了，即使还处于candidate状态，也开启这一轮新的选举，将上一次结果作废
    
    2.针对每个peer的每一轮日志备份（即追加日志操作 Logs Replication）：
       *无论Caller是否按顺序发送RPC，永远也无法保证Callee能按发送顺序接收到RPC，也永远无法保证按发送顺序收到响应。
        比如Caller发送一个带log的AE，重试了几次还是超时了，这一轮执行完毕；到下一轮，发送一个log更长的AE
        注意此时网络中可能有两个log长度不同的AE请求，即上一次发送的AE仍然滞留在网络中，
        而且可能后发出的长log的AE先到达follower，先发出的短log的AE后到达，
        如果follower采用覆盖策略，它假设后收到的log更新，则会导致follower自己只保存了更短的log，
        极端情况下
            有可能是短log的回复先于长log的回复到达leader，leader最终以为follower备份了长log，
            以为follower接受agree长log中的所有entry，从而提交这些entry，出大问题
        
        这里采取的方案是：允许Leader并发地乱序发送AE，防止被长耗时/超时的AE阻塞，极大地提高效率；
        follower在AE处理函数中增加逻辑：在判断两个log前缀一致的情况下，比较AE中的每个log entry，
        ①如果出现不一致（同index，不同term）entry，则说明follower log中次entry后续的entry都“可能”
        与Leader log中的entry不一致，全部丢弃；并把AE中的log entry全部append到对应位置。
        ②如果未出现不一致的entry，则无需操作


*20.为什么不需要持久化raft节点维护的commitIndex、lastApplied，经历crash-reboot后会不会由于没持久化lastApplied造成已提交的日志重复执行？
    CommitIndex不需要持久化：重启后Leader可以通过获取其他节点的日志保存情况（matchIndex[]）慢慢确认日志提交点位置
    LastApplied不需要持久化：每个Raft节点上的State Machine是易失性的Volatile，每次重启后需要从第一条log开始重放
                            所以无需持久化。如果是非易失性Non-Volatile的应用（比如某种DB数据库），那么就可能需要考虑持久化了


21.选举完成之后为啥要重置nextIndex[], matchIndex[]两个数组？
    这两个是数组是Leader节点在它的任期内维护的每个节点的状态信息，随着leader与follower通信慢慢维护的变量。
    nextIndex保存每个follower可能缺少的日志后缀位置，目的是用来加速日志备份，每次从末尾开始枚举follower缺少的日志后缀比较慢
    matchIndex保存每个follower已经备份了leader log中前多少条日志，用来确定leader可以提交前多少条日志，一个变相vote计数器
    节点的这两个状态可能在一个节点第一次成为Leader 和 第二次成为Leader这段时间中被其他Leader改变，后续安全使用可能需要额外检查

*22.Leader Completeness Property？
    Raft协议基于过半投票机制的性质（参考1.666）对Leader-Election过程和Log-Replication过程增加限制条件得到的特性
    用于保证选举出来的新Leader一定包含所有已经提交的log。以便新Leader当选后无需发送一大堆RPC确定当前已提交的所有日志。

    Leader-Election限制：选举leader时，节点只能投票给log比本地log更新或者一样新的候选节点。
    Log-Replication限制：新Leader不能备份旧Leader的log到其他节点，也不能提交旧Leader的log。

    log新旧判断：
        以下图s0和s4为例，它们的日志分别为log[1,2,4]、log[1,3]，分别包含3、2条小日志/条目/entry
        ·因为raft leader节点向follower节点备份日志时，只有日志中所以条目相同了才会投票给leader
            即Log-Replication操作逻辑上是一个全量备份/同步，只不过log是数组，可以只发送follower部分缺失的后缀即可。
        ·因为日志数组不支持插入/删除/修改，只允许append/overwrite（相当于给数组换一个后缀）
        所以越新的日志，最后一个entry的term号更大，如果term相同，数组越长的log越长
 
        从最后一条entry可以判断这两个log分别属于term为4、3的Leader。

        index 0   1   2   3
      node
      _s0     1   2   4      
       s1     1   2         
       s2     1   2          
       s3     1             
      *s4     1   3          

    假设如上状态：s4为leader，s0断连连接，term为5； 如果允许新leader s4备份或者提交旧leader的log会怎样
        s4会使用旧日志log[1,3]覆盖s1/2节点的旧日志log[1,2]，而旧Leader可能提交了日志log[1,2]（允许s0在term=4时提交旧日志log[1,2]）
        会使得已提交日志的部分条目被覆盖
            

23.引入snapshot快照机制压缩日志（Log Compaction）后，Leader备份日志（Log Replication）的任务有什么变化？
    快照机制说明：snapshot机制会时不时去除日志数组中一个已经提交并应用到上层状态机的前缀，将其以状态机快照的形式保存
        RPC调用前后日志长度可能发生变化，对于logs长度的Double-Check可以放宽
        （代码之前的版本这么做其实也没必要，冗余了，因为确保了RPC前后都是同一个Leader，而leader在自己的任期内只会append自己的log，除了snapshot不会删改）


24.Leader提交完日志后会把ACK合并到下一次心跳发给全部节点，落后leader的follower怎么处理这个信息？
    根据heartbeat中“上一个entry”的信息（prevLogIndex，prevLogTerm）判断自身log的前缀是否和leader的log相同
    如果这一段前缀是一样的，那么再根据请求中leader的commitIndex（即ACK）判断前缀中哪些条目可以commit。


25.raft层和应用层如何通信？
    raft层把需要应用层执行的指令发送到Golang Channel，应用层从这个固定长度的阻塞队列中读指令并执行
    应用层只有在创建Snapshot快照时才会调用raft层的snapshot()函数要求raft层压缩log


26.向与上层应用通信的消息队列（golang channel）投递消息时需要注意什么？
    首先，消息分为两种：log entry 和 snapshot
      1.必须要特别注意消息产生的顺序和消息存入队列的顺序，防止上层应用读到错误顺序的消息，旧状态覆盖新状态
    所有这里不要异步投递每个消息，怕乱序。
    【顺序：新snapshot在旧snapshot之后、未压缩的log-entry在snapshot之后】

      2.必须要特别注意这个消息队列可能阻塞的情况，在当前goroutine持有lock的情况下最好不要投递消息，
    因为上层app有可能调用raft层snapshot快照函数，尝试获取锁，极有可能deadlock。
    【循环依赖关系：raft.lock() -> mq.push() -> app.snapshot() -> raft.lock()】

    可以设计一个可自动扩容的非阻塞队列，用于按顺序存储这两种消息，然后后台按顺序读取非阻塞队列并投递


27.如何理解raft协议的“Strong Leadership”特点？
    1.raft协议保证了只有日志中包含旧Leader全部已提交日志条目的节点能当选Leader节点，即“Leader Completeness Property”
    2.每个任期只允许存在一个leader
    3.只有Leader能处理/应答客户端请求
    4.log数据只会从Leader流向Follower,所有节点上的log都需要与leader节点的同步


28.注意：leader发送rf.Logs切片Slice中的日志条目时需要Deep copy
    因为构造args参数到发送RPC这一小段时间内 释放了锁，所有rf.Logs切片底层引用的数组里面的值可能被其他任务修改（比如日志压缩）
    如果不Deep Copy 很可能发出错数据

https://raft.github.io/